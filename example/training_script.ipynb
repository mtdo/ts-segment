{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "from ignite.metrics import Loss\n",
    "from ignite.contrib.handlers.param_scheduler import LRScheduler\n",
    "\n",
    "from segmentation.datasets import MobiActV2\n",
    "from segmentation.models import SensorFCN\n",
    "from segmentation.engine import create_trainer, create_evaluator\n",
    "from segmentation.metrics import (\n",
    "    SamplewiseAccuracy,\n",
    "    MeanAccuracy,\n",
    "    MeanIoU,\n",
    "    FrequencyWeightedIoU,\n",
    ")\n",
    "from segmentation.logger import Logger\n",
    "from segmentation import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill parameter cell\n",
    "# Model params\n",
    "sensors = \"ago\"\n",
    "input_kernel_size = 5\n",
    "n_filters = 16\n",
    "smoothing_kernel_size = 0\n",
    "\n",
    "# Run params\n",
    "random_seed = 1234\n",
    "experiment = \"input_kernel_size\"\n",
    "gpu = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_channels = []\n",
    "if \"a\" in sensors:\n",
    "    sensor_channels.extend([\"acc_x\", \"acc_y\", \"acc_z\"])\n",
    "if \"g\" in sensors:\n",
    "    sensor_channels.extend([\"gyro_x\", \"gyro_y\", \"gyro_z\"])\n",
    "if \"o\" in sensors:\n",
    "    sensor_channels.extend([\"azimuth\", \"pitch\", \"roll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split\n",
    "np.random.seed(random_seed)\n",
    "users = np.arange(1, 68)\n",
    "np.random.shuffle(users)\n",
    "\n",
    "test_users = users[0:7]\n",
    "validation_users = users[7:14]\n",
    "train_users = users[14:]\n",
    "\n",
    "# Load datasets\n",
    "train_set = MobiActV2(\"data/MobiActV2/frames\", sensor_channels, train_users)\n",
    "validation_set = MobiActV2(\"data/MobiActV2/frames\", sensor_channels, validation_users)\n",
    "test_set = MobiActV2(\"data/MobiActV2/frames\", sensor_channels, test_users)\n",
    "n_classes = len(train_set.label_codes)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(gpu if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "model = SensorFCN(\n",
    "    n_input_channels=len(sensor_channels),\n",
    "    n_classes=int(n_classes),\n",
    "    input_kernel_size=int(input_kernel_size),\n",
    "    n_filters=int(n_filters),\n",
    "    smoothing_kernel_size=int(smoothing_kernel_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class weights\n",
    "class_weights = np.load(\"data/MobiActV2/class_weights.npy\")\n",
    "class_weights = torch.tensor(class_weights).to(device, dtype=torch.float)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer and evaluator engines\n",
    "trainer = create_trainer(model, optimizer, loss_fn, device)\n",
    "evaluator = create_evaluator(\n",
    "    model,\n",
    "    device,\n",
    "    metrics={\n",
    "        \"loss\": Loss(loss_fn),\n",
    "        \"samplewise_accuracy\": SamplewiseAccuracy(),\n",
    "        \"mean_accuracy\": MeanAccuracy(),\n",
    "        \"mean_iou\": MeanIoU(),\n",
    "        \"frequency_weighted_iou\": FrequencyWeightedIoU(),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Attach LR scheduler\n",
    "step_scheduler = StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "scheduler = LRScheduler(step_scheduler)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, scheduler)\n",
    "\n",
    "# Attach handler for training logging\n",
    "logger = Logger(evaluator, train_loader, validation_loader)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, logger)\n",
    "\n",
    "# Run trainer engine\n",
    "trainer.run(train_loader, max_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_metrics(logger.metrics, \"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_metrics(logger.metrics, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_tr, y_pred_tr = utils.predict_with_model(model, train_set, device)\n",
    "utils.plot_confusion_matrix(\n",
    "    y_true_tr, y_pred_tr, list(train_set.label_codes.keys()), normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_val, y_pred_val = utils.predict_with_model(model, validation_set, device)\n",
    "utils.plot_confusion_matrix(\n",
    "    y_true_val, y_pred_val, list(validation_set.label_codes.keys()), normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == \"input_kernel_size\":\n",
    "    name = str(input_kernel_size)\n",
    "if experiment == \"n_filters\":\n",
    "    name = str(n_filters)\n",
    "if experiment == \"sensors\":\n",
    "    name = sensors\n",
    "if experiment == \"smoothing_kernel_size\":\n",
    "    name = f\"{str(smoothing_kernel_size)}\"\n",
    "\n",
    "output_dir = f\"output_asd/{random_seed}/{experiment}/{name}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"model.pt\"))\n",
    "\n",
    "# Save model log/history\n",
    "f = open(os.path.join(output_dir, \"hist.p\"), \"wb\")\n",
    "pickle.dump(logger.metrics, f)\n",
    "f.close()\n",
    "\n",
    "# Save number of parameters\n",
    "f = open(os.path.join(output_dir, \"n_params.p\"), \"wb\")\n",
    "pickle.dump(sum(p.numel() for p in model.parameters()), f)\n",
    "f.close()\n",
    "\n",
    "# Save training and validation ground truth and predictions\n",
    "np.save(os.path.join(output_dir, \"y_true_tr.npy\"), y_true_tr)\n",
    "np.save(os.path.join(output_dir, \"y_pred_tr.npy\"), y_pred_tr)\n",
    "np.save(os.path.join(output_dir, \"y_true_val.npy\"), y_true_val)\n",
    "np.save(os.path.join(output_dir, \"y_pred_val.npy\"), y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
